{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mind Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_from_tsfile\n",
    "import numpy as np # for some mathematical operations\n",
    "def load_data(DATA_PATH,t):\n",
    "    if t=='train':\n",
    "        train_x, train_y = load_from_tsfile(DATA_PATH + \"/MindReading/MindReading_TRAIN.ts\")\n",
    "        return [train_x,train_y]\n",
    "    elif t=='test':\n",
    "        test_x, test_y = load_from_tsfile(DATA_PATH + \"/MindReading/MindReading_TEST.ts\")\n",
    "        return [test_x, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the load_data function\n",
    "[data, data_y] = load_data(\"datasets\",'train')  # 'path', 'test'/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time series:\n",
      "[[ 4.4678e-13  3.9723e-12  1.1486e-11 ...  1.9081e-11  1.8362e-11\n",
      "   1.8827e-11]\n",
      " [ 1.1228e-12  4.0343e-12 -7.8352e-13 ... -4.5558e-12 -5.0939e-12\n",
      "  -4.4572e-12]\n",
      " [-1.1288e-11 -8.9216e-12 -4.1732e-12 ...  5.8279e-12  9.3328e-12\n",
      "   5.6202e-12]\n",
      " ...\n",
      " [-1.8000e-11 -1.7135e-11 -9.7925e-12 ... -7.3061e-12 -8.2804e-12\n",
      "  -1.1478e-11]\n",
      " [-7.6181e-12 -4.2700e-12 -6.4728e-12 ... -1.0940e-11 -5.6271e-12\n",
      "  -2.8647e-12]\n",
      " [-1.5248e-11 -1.4270e-11 -7.2255e-12 ...  8.7034e-12  4.5966e-12\n",
      "   1.5183e-12]] \n",
      "\n",
      "First target:\n",
      "5 \n",
      "\n",
      "Shape of train dataset:\n",
      "(727, 204, 200)\n"
     ]
    }
   ],
   "source": [
    "print('First time series:')\n",
    "print(data[0],\"\\n\")\n",
    "print('First target:')\n",
    "print(data_y[0],\"\\n\")\n",
    "print('Shape of train dataset:') #(samples, features,timestamps) \n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "def standarize(data):\n",
    "    scaler = TimeSeriesScalerMeanVariance(mu=0.0, std=1.0)  # Standardize to mean=0, std=1\n",
    "    scaled_data_3d = scaler.fit_transform(data)\n",
    "    return scaled_data_3d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (727, 204, 200)\n",
      "Reshaped shape: (727, 200, 204)\n"
     ]
    }
   ],
   "source": [
    "# Transform from (samples, features,timestamps) to (samples, timestamps, features) to apply standarisation\n",
    "reshaped_data = np.transpose(data, (0, 2, 1))\n",
    "print(\"Original shape:\", data.shape)          # (instances, features, timepoints)\n",
    "print(\"Reshaped shape:\", reshaped_data.shape) # (instances, timepoints, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time series:\n",
      "[[-2.17755427 -0.05407343 -2.42725565 ... -2.34694313 -0.21684994\n",
      "  -1.92298355]\n",
      " [-1.4915501   0.55616434 -2.04298104 ... -2.07882616  0.54557664\n",
      "  -1.78658807]\n",
      " [-0.02951625 -0.45362984 -1.27189856 ...  0.19706845  0.04395684\n",
      "  -0.80413621]\n",
      " ...\n",
      " [ 1.44833714 -1.24428338  0.35215858 ...  0.9677575  -0.97331027\n",
      "   1.41736674]\n",
      " [ 1.30843239 -1.3570668   0.92131176 ...  0.66576171  0.23653894\n",
      "   0.84461731]\n",
      " [ 1.39891321 -1.22361724  0.31843063 ... -0.32537218  0.8655904\n",
      "   0.41530628]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_data=standarize(reshaped_data)\n",
    "# scaled_data\n",
    "print('First time series:')\n",
    "print(scaled_data[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727, 200, 204)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: intrinsic metrics before vs. after Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS:\n",
    "* Representation Entropy correlation based\n",
    "* Variance\n",
    "* Redundancy Rate RED\n",
    "\n",
    "TO DO:\n",
    "* Information Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation Entropy\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def compute_representation_entropy(data):\n",
    "    \"\"\"\n",
    "    Compute Representation Entropy (RE) of a multivariate dataset.\n",
    "    \n",
    "    Args:\n",
    "        data (numpy.ndarray): 2D-Data with shape (samples, features).\n",
    "    \n",
    "    Returns:\n",
    "        float: Representation Entropy (RE).\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the covariance matrix of the dataset (features x features)\n",
    "    #covariance_matrix = np.cov(data, rowvar=False)  # rowvar=False means variables are columns\n",
    "\n",
    "    block_size=100\n",
    "    data_centered = data - np.mean(data, axis=0)\n",
    "    num_features = data.shape[1]\n",
    "    covariance_matrix = np.zeros((num_features, num_features), dtype=np.float64)\n",
    "\n",
    "    for i in range(0, num_features, block_size):\n",
    "        for j in range(i, num_features, block_size):\n",
    "            block_i = data_centered[:, i:i+block_size]\n",
    "            block_j = data_centered[:, j:j+block_size]\n",
    "            block_cov = np.dot(block_i.T, block_j) / (data.shape[0] - 1)\n",
    "            covariance_matrix[i:i+block_size, j:j+block_size] = block_cov\n",
    "            if i != j:\n",
    "                covariance_matrix[j:j+block_size, i:i+block_size] = block_cov.T\n",
    "\n",
    "\n",
    "    # # Step 2: Compute eigenvalues of the covariance matrix\n",
    "    # eigenvalues = np.linalg.eigvals(covariance_matrix) THIS METHOD WAS REPLACED BC OF INSTABILITY\n",
    "    eigenvalues, eigenvectors = eigh(covariance_matrix)\n",
    "\n",
    "    # Step 3: Normalize the eigenvalues to act as probabilities\n",
    "    eigenvalues_sum = np.sum(eigenvalues)\n",
    "    normalized_eigenvalues = eigenvalues / eigenvalues_sum\n",
    "\n",
    "    # Step 4: Compute Representation Entropy using the formula\n",
    "    representation_entropy = -np.sum(normalized_eigenvalues * np.log(normalized_eigenvalues))\n",
    "\n",
    "    return representation_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145400, 204)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to flatten the Time Dimension\n",
    "data_flattened = scaled_data.reshape(-1, scaled_data.shape[2])\n",
    "np.shape(data_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.584673534531154"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_representation_entropy(data_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall variance: 0.9999999999999994\n",
      "Redundancy Rate (Correlation-Based): 0.13251974452129833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# calculate variance\n",
    "overall_variance = data_flattened.var().mean()\n",
    "print('overall variance:', overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = pd.DataFrame(data_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "avg_corr = (corr_matrix.values.sum() - len(corr_matrix)) / (len(corr_matrix) * (len(corr_matrix) - 1))\n",
    "redundancy_rate = avg_corr\n",
    "print(\"Redundancy Rate (Correlation-Based):\", redundancy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TEST dataset\n",
    "[TESTdata, TESTdata_y] = load_data(\"datasets\",'test')  # 'path', 'test'/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (727, 204, 200)\n",
      "Reshaped shape: (727, 200, 204)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the TEST data\n",
    "\n",
    "reshaped_TESTdata = np.transpose(TESTdata, (0, 2, 1))\n",
    "print(\"Original shape:\", data.shape)          # (instances, features, timepoints)\n",
    "print(\"Reshaped shape:\", reshaped_data.shape) # (instances, timepoints, features)\n",
    "scaled_TESTdata=standarize(reshaped_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before Representation entropy:  3.6266400216236834\n",
      "before overall variance: 1.000000000000002\n",
      "before Redundancy Rate (Correlation-Based): 0.12879010061670176\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for original data_TEST\n",
    "\n",
    "# Compute representation entropy\n",
    "before_TESTdata_flattened = scaled_TESTdata.reshape(-1, scaled_TESTdata.shape[2])\n",
    "before_representation_entropy = compute_representation_entropy(before_TESTdata_flattened)\n",
    "print('before Representation entropy: ', before_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "before_overall_variance = before_TESTdata_flattened.var().mean()\n",
    "print('before overall variance:', before_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "before_corr_matrix = pd.DataFrame(before_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "before_avg_corr = (before_corr_matrix.values.sum() - len(before_corr_matrix)) / (len(before_corr_matrix) * (len(before_corr_matrix) - 1))\n",
    "before_redundancy_rate = before_avg_corr\n",
    "print(\"before Redundancy Rate (Correlation-Based):\", before_redundancy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130600, 204)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(before_TESTdata_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection 1: CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "def compute_dcpcs(data, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compute Descriptive Common Principal Components (DCPCs) for a set of multivariate time series.\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray of shape (num_samples, num_features, time_steps), the time-series dataset.\n",
    "    - variance_threshold: float, the cumulative variance explained to determine the number of PCs.\n",
    "\n",
    "    Returns:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    \"\"\"\n",
    "    num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "    # Step 1: Compute PCs for each MTS item\n",
    "    pc_matrices = []  # Store PC loadings for each sample\n",
    "    for sample in range(num_samples):\n",
    "        # Compute correlation matrix for each sample\n",
    "        correlation_matrix = np.corrcoef(data[sample])\n",
    "        # Perform PCA on the correlation matrix\n",
    "        pca = PCA()\n",
    "        pca.fit(correlation_matrix)\n",
    "        pc_matrices.append(pca.components_[:pca.n_components_])\n",
    "\n",
    "    # Step 2: Compute DCPCs across all samples using SVD\n",
    "    all_pc_matrices = np.concatenate(pc_matrices, axis=0)  # Combine PC loadings from all samples\n",
    "    dcpc_covariance = all_pc_matrices.T @ all_pc_matrices\n",
    "    eigvals, eigvecs = np.linalg.eigh(dcpc_covariance)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, sorted_indices]  # Sort eigenvectors by eigenvalues\n",
    "\n",
    "    # Select DCPCs explaining the desired variance threshold\n",
    "    cumulative_variance = np.cumsum(eigvals[sorted_indices]) / np.sum(eigvals)\n",
    "    num_dcpcs = np.searchsorted(cumulative_variance, variance_threshold) + 1\n",
    "    dcpc_loadings = eigvecs[:, :num_dcpcs].T\n",
    "\n",
    "    return dcpc_loadings\n",
    "\n",
    "def cluster_features(dcpc_loadings, n_clusters):\n",
    "    \"\"\"\n",
    "    Cluster features based on their DCPC loadings using K-means.\n",
    "\n",
    "    Parameters:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    - n_clusters: int, number of clusters.\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: ndarray of shape (num_features,), cluster assignments for each feature.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(dcpc_loadings.T)\n",
    "    return cluster_labels\n",
    "\n",
    "def rank_features(dcpc_loadings, cluster_labels):\n",
    "    \"\"\"\n",
    "    Rank features within each cluster based on their contribution to DCPCs.\n",
    "\n",
    "    Parameters:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    - cluster_labels: ndarray of shape (num_features,), cluster assignments for each feature.\n",
    "\n",
    "    Returns:\n",
    "    - ranked_features: dict, keys are cluster labels, values are ranked feature indices.\n",
    "    \"\"\"\n",
    "    ranked_features = {}\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        cluster_loadings = dcpc_loadings[:, cluster_indices]\n",
    "        scores = np.linalg.norm(cluster_loadings, axis=0)  # L2 norm of loadings\n",
    "        ranking = cluster_indices[np.argsort(scores)[::-1]]  # Sort by descending contribution\n",
    "        ranked_features[cluster] = ranking\n",
    "    return ranked_features\n",
    "\n",
    "def select_top_features(ranked_features, top_n=1):\n",
    "    \"\"\"\n",
    "    Select top-ranked features from each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - ranked_features: dict, keys are cluster labels, values are ranked feature indices.\n",
    "    - top_n: int, number of features to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: list, indices of selected features.\n",
    "    \"\"\"\n",
    "    selected_features = []\n",
    "    for features in ranked_features.values():\n",
    "        selected_features.extend(features[:top_n])\n",
    "    return selected_features\n",
    "\n",
    "def clever_hybrid(data, variance_threshold=0.8, n_clusters=None, top_n=1):\n",
    "    \"\"\"\n",
    "    Perform feature selection using the CLeVer-Hybrid algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray of shape (num_samples, num_features, time_steps), the time-series dataset.\n",
    "    - variance_threshold: float, variance threshold for selecting DCPCs.\n",
    "    - n_clusters: int, number of clusters (if None, sqrt of num_features is used).\n",
    "    - top_n: int, number of features to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: list, indices of selected features.\n",
    "    \"\"\"\n",
    "    num_samples, num_features, _ = data.shape\n",
    "    if n_clusters is None:\n",
    "        n_clusters = int(np.sqrt(num_features))\n",
    "\n",
    "    # Step 1: Compute DCPCs\n",
    "    dcpc_loadings = compute_dcpcs(data, variance_threshold)\n",
    "\n",
    "    # Step 2: Cluster features based on DCPC loadings\n",
    "    cluster_labels = cluster_features(dcpc_loadings, n_clusters)\n",
    "\n",
    "    # Step 3: Rank features within clusters\n",
    "    ranked_features = rank_features(dcpc_loadings, cluster_labels)\n",
    "\n",
    "    # Step 4: Select top features from each cluster\n",
    "    selected_features = select_top_features(ranked_features, top_n)\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727, 204, 200)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data_ift= np.transpose(scaled_data, (0, 2, 1))\n",
    "np.shape(scaled_data_ift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features CLeVer Hybrid:  [47, 45, 160, 190, 141, 109, 118, 132, 81, 41, 121, 51, 181, 143, 4, 169, 0, 125, 21, 20, 193, 1, 199, 5, 58]\n"
     ]
    }
   ],
   "source": [
    "selected_features_CLeVerH=clever_hybrid(scaled_data_ift, n_clusters=25,top_n=1)\n",
    "print(\"Selected features CLeVer Hybrid: \", selected_features_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 200, 204)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (653, 200, 25)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerH = scaled_TESTdata[:, :, selected_features_CLeVerH]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Hybrid Representation entropy:  2.825385295447174\n",
      "CLEVER Hybrid overall variance: 0.9999999999999997\n",
      "CLEVER Hybrid Redundancy Rate (Correlation-Based): 0.13899326959469616\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerH\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERH_TESTdata_flattened = selected_TESTdata_CLeVerH.reshape(-1, selected_TESTdata_CLeVerH.shape[2])\n",
    "CLEVERH_representation_entropy = compute_representation_entropy(CLEVERH_TESTdata_flattened)\n",
    "print('CLEVER Hybrid Representation entropy: ', CLEVERH_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERH_overall_variance = CLEVERH_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Hybrid overall variance:', CLEVERH_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERH_corr_matrix = pd.DataFrame(CLEVERH_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERH_avg_corr = (CLEVERH_corr_matrix.values.sum() - len(CLEVERH_corr_matrix)) / (len(CLEVERH_corr_matrix) * (len(CLEVERH_corr_matrix) - 1))\n",
    "CLEVERH_redundancy_rate = CLEVERH_avg_corr\n",
    "print(\"CLEVER Hybrid Redundancy Rate (Correlation-Based):\", CLEVERH_redundancy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection 2: CLeVer Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "def clever_cluster(data, n_clusters=None, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    CLeVer-Cluster implementation.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array of shape (samples, features, time_steps)\n",
    "    - n_clusters: Number of feature clusters (if None, heuristic is used)\n",
    "    - variance_threshold: Minimum variance explained by selected PCs\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: List of representative feature indices for each cluster\n",
    "    \"\"\"\n",
    "    num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "    # Step 1: Compute DCPC loadings\n",
    "    dcpc_loadings = compute_dcpcs(data, variance_threshold=variance_threshold)  # Shape: (components, features)\n",
    "\n",
    "    # Step 2: Transpose DCPC loadings to cluster features\n",
    "    feature_embeddings = dcpc_loadings.T  # Shape: (features, components)\n",
    "\n",
    "    # Step 3: Determine number of clusters\n",
    "    if n_clusters is None:\n",
    "        n_clusters = int(np.sqrt(num_features))  # Heuristic for cluster count\n",
    "\n",
    "    # Step 4: Perform K-means clustering on DCPC loadings\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_embeddings)\n",
    "\n",
    "    # Step 5: Select representative features (closest to cluster centroids)\n",
    "    selected_features = []\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        centroid = kmeans.cluster_centers_[cluster]\n",
    "\n",
    "        # Find the feature closest to the centroid\n",
    "        distances = np.linalg.norm(feature_embeddings[cluster_indices] - centroid, axis=1)\n",
    "        representative_feature = cluster_indices[np.argmin(distances)]\n",
    "        selected_features.append(representative_feature)\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLeVer Cluster Selected feature indices: [47, 133, 160, 190, 141, 109, 118, 132, 81, 41, 121, 51, 181, 143, 4, 169, 0, 125, 21, 20, 193, 165, 199, 5, 58]\n"
     ]
    }
   ],
   "source": [
    "selected_features_CLeVerC = clever_cluster(scaled_data_ift,n_clusters=25)\n",
    "print(f'CLeVer Cluster Selected feature indices: {selected_features_CLeVerC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 200, 204)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (653, 200, 25)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerC = scaled_TESTdata[:, :, selected_features_CLeVerC]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Cluster Representation entropy:  2.838692187395427\n",
      "CLEVER Cluster overall variance: 1.0000000000000002\n",
      "CLEVER Cluster Redundancy Rate (Correlation-Based): 0.13755710813746946\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerC\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERC_TESTdata_flattened = selected_TESTdata_CLeVerC.reshape(-1, selected_TESTdata_CLeVerC.shape[2])\n",
    "CLEVERC_representation_entropy = compute_representation_entropy(CLEVERC_TESTdata_flattened)\n",
    "print('CLEVER Cluster Representation entropy: ', CLEVERC_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERC_overall_variance = CLEVERC_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Cluster overall variance:', CLEVERC_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERC_corr_matrix = pd.DataFrame(CLEVERC_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERC_avg_corr = (CLEVERC_corr_matrix.values.sum() - len(CLEVERC_corr_matrix)) / (len(CLEVERC_corr_matrix) * (len(CLEVERC_corr_matrix) - 1))\n",
    "CLEVERC_redundancy_rate = CLEVERC_avg_corr\n",
    "print(\"CLEVER Cluster Redundancy Rate (Correlation-Based):\", CLEVERC_redundancy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection 3: CLeVer Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clever_ranking(data, num_features_to_select=5, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    CLeVer Ranking method for feature selection.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array of shape (samples, features, time_steps)\n",
    "    - num_features_to_select: Number of top-ranked features to select\n",
    "    - variance_threshold: Variance threshold for PCA\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: List of indices of the top-ranked features\n",
    "    \"\"\"\n",
    "    # Step 1: Compute DCPC loadings\n",
    "    dcpc_loadings = compute_dcpcs(data,variance_threshold=variance_threshold)\n",
    "\n",
    "    # Step 2: Rank features based on their contribution to the DCPCs\n",
    "    feature_scores = np.linalg.norm(dcpc_loadings, axis=1)  # L2 norm of DCPC loadings\n",
    "    ranked_features = np.argsort(feature_scores)[::-1]  # Sort in descending order\n",
    "\n",
    "    # Step 3: Select top features\n",
    "    selected_features = ranked_features[:num_features_to_select]\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLeVer Rank Selected feature indices: [ 22   8   3  44  76  19  30  31  14 107  59  39  97   4   6  79 126  26\n",
      "  42 124 123  49 103 106  33]\n"
     ]
    }
   ],
   "source": [
    "selected_features_CLeVerR = clever_ranking(scaled_data_ift, num_features_to_select=25)\n",
    "print(f'CLeVer Rank Selected feature indices: {selected_features_CLeVerR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (653, 200, 25)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerR = scaled_TESTdata[:, :, selected_features_CLeVerR]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Cluster Representation entropy:  2.790011001438379\n",
      "CLEVER Cluster overall variance: 1.0000000000000004\n",
      "CLEVER Cluster Redundancy Rate (Correlation-Based): 0.14052007920900758\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerR\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERR_TESTdata_flattened = selected_TESTdata_CLeVerR.reshape(-1, selected_TESTdata_CLeVerR.shape[2])\n",
    "CLEVERR_representation_entropy = compute_representation_entropy(CLEVERR_TESTdata_flattened)\n",
    "print('CLEVER Cluster Representation entropy: ', CLEVERR_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERR_overall_variance = CLEVERR_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Cluster overall variance:', CLEVERR_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERR_corr_matrix = pd.DataFrame(CLEVERR_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERR_avg_corr = (CLEVERR_corr_matrix.values.sum() - len(CLEVERR_corr_matrix)) / (len(CLEVERR_corr_matrix) * (len(CLEVERR_corr_matrix) - 1))\n",
    "CLEVERR_redundancy_rate = CLEVERR_avg_corr\n",
    "print(\"CLEVER Cluster Redundancy Rate (Correlation-Based):\", CLEVERR_redundancy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Perform Timeseries-k-Means and evaluate clustering performance UNSUPERVISED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering evaluation Metrics:\n",
    "* Silhouette \n",
    "* Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTW Time series clsutering erfolgreich 133 min\n",
    "clustering of training dataset not required, commented out on last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW k-means\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "print(\"DTW k-means\")\n",
    "sdtw_km = TimeSeriesKMeans(n_clusters=5,\n",
    "                           metric=\"dtw\",\n",
    "                           verbose=True,\n",
    "                           random_state=seed)\n",
    "#y_pred = sdtw_km.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering should be done on the TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 200, 204)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thefit_predict(X, y=None)\n",
    "Fit k-means clustering using X and then predict the closest cluster each time series in X belongs to.\n",
    "\n",
    "Parameters:\n",
    "Xarray-like of shape=(n_ts, sz, d)\n",
    "n_ts: instance, sz:timestamps, d:features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73226.986 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   24.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39979.520 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39857.772 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39817.676 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   27.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39801.773 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39800.592 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39800.592 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:   23.7s\n"
     ]
    }
   ],
   "source": [
    "before_y_pred = sdtw_km.fit_predict(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 4, 3, 4, 1, 2, 3, 2, 2, 1, 4, 4, 4, 1, 4, 2, 1, 3, 3, 4,\n",
       "       3, 2, 3, 3, 1, 1, 1, 2, 4, 2, 1, 1, 4, 1, 0, 0, 2, 4, 0, 1, 2, 1,\n",
       "       0, 1, 0, 3, 1, 4, 4, 4, 1, 2, 4, 2, 0, 1, 4, 4, 3, 0, 3, 2, 1, 1,\n",
       "       1, 1, 1, 4, 0, 2, 3, 4, 2, 4, 1, 1, 0, 1, 0, 1, 3, 2, 2, 2, 1, 1,\n",
       "       4, 0, 3, 4, 1, 3, 3, 4, 3, 0, 0, 0, 4, 0, 2, 3, 0, 1, 3, 4, 0, 3,\n",
       "       3, 3, 1, 1, 1, 4, 1, 2, 2, 1, 0, 1, 4, 1, 4, 3, 4, 3, 2, 4, 1, 1,\n",
       "       4, 1, 3, 2, 1, 1, 4, 1, 4, 4, 1, 3, 4, 0, 2, 2, 1, 2, 0, 1, 3, 4,\n",
       "       1, 1, 4, 4, 3, 1, 4, 3, 2, 1, 3, 1, 3, 0, 0, 2, 2, 4, 1, 0, 1, 4,\n",
       "       3, 0, 2, 3, 1, 2, 1, 2, 0, 2, 1, 4, 1, 1, 3, 3, 4, 1, 3, 4, 1, 1,\n",
       "       1, 0, 3, 2, 1, 4, 4, 4, 0, 0, 2, 0, 1, 1, 4, 1, 4, 4, 3, 3, 4, 3,\n",
       "       4, 2, 3, 0, 4, 1, 1, 1, 4, 0, 4, 2, 2, 2, 3, 4, 2, 4, 1, 1, 3, 1,\n",
       "       4, 0, 2, 1, 1, 3, 0, 3, 1, 4, 4, 1, 1, 4, 4, 4, 1, 2, 0, 4, 3, 4,\n",
       "       2, 4, 4, 2, 4, 1, 2, 1, 3, 1, 2, 2, 3, 0, 2, 0, 3, 3, 1, 0, 2, 4,\n",
       "       4, 1, 1, 4, 0, 4, 3, 2, 3, 3, 2, 1, 2, 4, 4, 2, 3, 4, 4, 3, 4, 3,\n",
       "       2, 0, 3, 1, 2, 4, 2, 2, 2, 1, 2, 3, 3, 4, 3, 0, 1, 1, 2, 4, 0, 1,\n",
       "       4, 2, 2, 4, 1, 4, 4, 2, 0, 4, 2, 4, 1, 4, 4, 4, 2, 1, 2, 1, 3, 0,\n",
       "       2, 4, 4, 2, 4, 0, 1, 4, 1, 4, 4, 1, 0, 4, 4, 0, 2, 1, 1, 3, 1, 4,\n",
       "       1, 4, 1, 3, 4, 1, 4, 2, 2, 4, 1, 0, 3, 2, 4, 4, 1, 0, 1, 3, 3, 1,\n",
       "       1, 1, 1, 1, 3, 4, 1, 4, 4, 0, 4, 2, 4, 4, 1, 1, 4, 3, 1, 0, 4, 1,\n",
       "       1, 1, 0, 1, 4, 1, 0, 0, 2, 1, 4, 4, 4, 2, 1, 3, 4, 1, 4, 4, 1, 2,\n",
       "       1, 3, 2, 4, 3, 4, 3, 4, 0, 1, 1, 3, 3, 2, 1, 1, 0, 2, 1, 3, 1, 4,\n",
       "       3, 3, 0, 1, 1, 3, 1, 4, 3, 1, 3, 3, 1, 2, 3, 4, 4, 2, 4, 4, 3, 1,\n",
       "       1, 2, 1, 1, 4, 0, 3, 1, 1, 4, 0, 4, 4, 1, 1, 1, 1, 3, 3, 4, 3, 4,\n",
       "       4, 3, 2, 0, 4, 4, 3, 0, 1, 4, 3, 2, 1, 2, 0, 3, 1, 2, 1, 1, 3, 1,\n",
       "       1, 1, 3, 2, 4, 4, 0, 2, 3, 4, 1, 0, 4, 1, 2, 4, 1, 3, 3, 0, 0, 2,\n",
       "       1, 1, 1, 3, 0, 4, 1, 2, 1, 0, 1, 3, 4, 1, 0, 2, 1, 4, 1, 3, 2, 0,\n",
       "       4, 1, 3, 4, 3, 0, 2, 4, 3, 0, 1, 3, 4, 2, 3, 4, 1, 1, 3, 4, 3, 1,\n",
       "       4, 2, 3, 0, 1, 4, 0, 1, 3, 2, 3, 4, 4, 1, 4, 1, 4, 4, 2, 1, 0, 1,\n",
       "       4, 4, 3, 1, 1, 4, 4, 1, 4, 4, 4, 1, 2, 3, 0, 1, 3, 2, 4, 3, 1, 4,\n",
       "       1, 1, 4, 4, 1, 4, 4, 1, 0, 1, 2, 2, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before Silhouette Score: 0.00491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "labels = before_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdata_flattened_instances = scaled_TESTdata.reshape(scaled_TESTdata.shape[0], -1)  \n",
    "\n",
    "before_silhouette_avg = silhouette_score(scaled_TESTdata_flattened_instances, labels, metric='euclidean')\n",
    "print(f\"before Silhouette Score: {before_silhouette_avg:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before Davies-Bouldin Index: 8.84594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "before_db_index = davies_bouldin_score(scaled_TESTdata_flattened_instances, labels)\n",
    "print(f\"before Davies-Bouldin Index: {before_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS1: CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 200, 25)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_TESTdata_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8380.213 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4766.426 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4747.937 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4740.144 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4735.243 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4733.682 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732.951 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732.677 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732.677 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVER_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Hybrid Silhouette Score: 0.00582\n",
      "CLEVER Hybrid Davies-Bouldin Index: 8.36665\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CH = CLEVER_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCH_flattened_instances = selected_TESTdata_CLeVerH.reshape(selected_TESTdata_CLeVerH.shape[0], -1)  \n",
    "\n",
    "CLEVERH_silhouette_avg = silhouette_score(scaled_TESTdataCH_flattened_instances, labels_CH, metric='euclidean')\n",
    "print(f\"CLEVER Hybrid Silhouette Score: {CLEVERH_silhouette_avg:.5f}\")\n",
    "CLEVERH_db_index = davies_bouldin_score(scaled_TESTdataCH_flattened_instances, labels_CH)\n",
    "print(f\"CLEVER Hybrid Davies-Bouldin Index: {CLEVERH_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS2: CLeVer Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8386.107 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4783.352 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760.471 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753.989 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4751.737 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750.229 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749.856 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749.856 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.1s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVERC_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Cluster Silhouette Score: 0.00337\n",
      "CLEVER Cluster Davies-Bouldin Index: 9.87220\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CC = CLEVERC_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCC_flattened_instances = selected_TESTdata_CLeVerC.reshape(selected_TESTdata_CLeVerC.shape[0], -1)  \n",
    "\n",
    "CLEVERC_silhouette_avg = silhouette_score(scaled_TESTdataCC_flattened_instances, labels_CC, metric='euclidean')\n",
    "print(f\"CLEVER Cluster Silhouette Score: {CLEVERC_silhouette_avg:.5f}\")\n",
    "CLEVERC_db_index = davies_bouldin_score(scaled_TESTdataCC_flattened_instances, labels_CC)\n",
    "print(f\"CLEVER Cluster Davies-Bouldin Index: {CLEVERC_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS3: CLeVer Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8257.020 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4740.994 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722.911 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714.943 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4709.386 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705.970 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4703.345 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4701.401 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700.597 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700.017 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4699.850 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4699.850 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    2.0s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVERR_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Rank Silhouette Score: 0.00288\n",
      "CLEVER Rank Davies-Bouldin Index: 9.42421\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CR = CLEVERR_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCR_flattened_instances = selected_TESTdata_CLeVerR.reshape(selected_TESTdata_CLeVerR.shape[0], -1)  \n",
    "\n",
    "CLEVERR_silhouette_avg = silhouette_score(scaled_TESTdataCR_flattened_instances, labels_CR, metric='euclidean')\n",
    "print(f\"CLEVER Rank Silhouette Score: {CLEVERR_silhouette_avg:.5f}\")\n",
    "CLEVERR_db_index = davies_bouldin_score(scaled_TESTdataCR_flattened_instances, labels_CR)\n",
    "print(f\"CLEVER Rank Davies-Bouldin Index: {CLEVERR_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validierung mit clustering accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare clustering vs labels\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(true_labels, predicted_labels):\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Use the Hungarian algorithm to find the optimal assignment of clusters\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)  # Maximize the matching (negative to maximize)\n",
    "    \n",
    "    # Calculate accuracy based on optimal matching\n",
    "    accuracy = cm[row_ind, col_ind].sum() / len(true_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 5, 2, 1, 1, 5, 2, 1, 3, 2, 1, 1, 1, 5, 1, 1, 2, 2, 4, 3, 2,\n",
       "       5, 3, 1, 4, 4, 1, 5, 5, 1, 5, 1, 3, 3, 3, 2, 5, 2, 5, 1, 3, 4, 2,\n",
       "       5, 2, 2, 5, 5, 1, 1, 4, 2, 4, 2, 5, 3, 2, 3, 1, 1, 1, 5, 1, 5, 2,\n",
       "       2, 1, 1, 1, 2, 4, 5, 3, 3, 2, 1, 3, 1, 2, 3, 4, 3, 5, 5, 2, 3, 4,\n",
       "       4, 5, 1, 1, 4, 2, 1, 5, 5, 5, 1, 5, 4, 5, 5, 4, 3, 2, 4, 1, 1, 1,\n",
       "       5, 2, 1, 2, 1, 4, 2, 1, 2, 1, 4, 3, 4, 4, 1, 5, 1, 1, 1, 4, 2, 4,\n",
       "       1, 3, 2, 3, 1, 4, 3, 1, 2, 2, 4, 2, 2, 4, 2, 4, 5, 1, 1, 1, 2, 5,\n",
       "       2, 4, 4, 2, 1, 5, 3, 3, 1, 5, 3, 1, 2, 1, 3, 3, 4, 5, 1, 2, 4, 1,\n",
       "       5, 4, 5, 2, 1, 1, 2, 2, 2, 4, 2, 4, 4, 5, 1, 4, 3, 1, 2, 1, 4, 5,\n",
       "       4, 3, 1, 3, 2, 1, 3, 5, 2, 3, 3, 1, 4, 3, 2, 4, 1, 4, 4, 3, 4, 5,\n",
       "       3, 1, 1, 3, 4, 5, 2, 3, 4, 3, 5, 2, 2, 2, 2, 1, 1, 1, 4, 4, 3, 4,\n",
       "       3, 4, 2, 2, 1, 2, 1, 1, 5, 3, 2, 2, 4, 4, 1, 5, 1, 1, 4, 4, 2, 3,\n",
       "       2, 2, 4, 2, 3, 4, 4, 5, 1, 1, 1, 2, 4, 2, 4, 4, 5, 1, 1, 5, 4, 2,\n",
       "       1, 2, 2, 2, 5, 2, 1, 2, 5, 2, 2, 5, 5, 5, 2, 5, 1, 2, 2, 1, 2, 2,\n",
       "       1, 5, 5, 2, 1, 4, 2, 3, 4, 4, 3, 2, 5, 1, 4, 3, 2, 1, 2, 5, 5, 3,\n",
       "       5, 3, 4, 4, 4, 4, 2, 1, 3, 3, 2, 2, 2, 3, 5, 5, 5, 1, 5, 3, 1, 5,\n",
       "       5, 1, 4, 1, 2, 2, 5, 5, 4, 5, 1, 2, 2, 2, 5, 4, 1, 5, 1, 3, 3, 1,\n",
       "       2, 4, 3, 4, 4, 1, 1, 5, 4, 5, 1, 2, 1, 5, 1, 3, 2, 1, 5, 4, 1, 5,\n",
       "       1, 5, 4, 2, 2, 4, 5, 2, 4, 3, 4, 1, 4, 4, 3, 5, 1, 3, 2, 2, 2, 1,\n",
       "       1, 3, 3, 1, 5, 4, 4, 3, 5, 3, 4, 2, 5, 4, 4, 4, 4, 5, 3, 4, 2, 1,\n",
       "       1, 2, 4, 4, 3, 4, 2, 3, 4, 5, 1, 4, 5, 3, 2, 3, 1, 3, 4, 1, 4, 1,\n",
       "       3, 2, 2, 1, 4, 2, 4, 3, 5, 5, 2, 1, 3, 4, 5, 2, 4, 5, 4, 1, 2, 3,\n",
       "       2, 5, 2, 3, 1, 4, 4, 3, 3, 4, 4, 3, 5, 5, 4, 4, 4, 4, 1, 1, 1, 2,\n",
       "       3, 1, 3, 4, 4, 5, 5, 5, 2, 1, 2, 3, 1, 2, 2, 1, 1, 5, 3, 1, 4, 2,\n",
       "       1, 1, 5, 1, 3, 2, 3, 3, 1, 1, 4, 3, 2, 2, 5, 2, 2, 3, 4, 5, 1, 4,\n",
       "       5, 1, 4, 5, 5, 3, 5, 5, 2, 5, 3, 5, 1, 5, 4, 5, 5, 5, 1, 2, 4, 5,\n",
       "       2, 3, 5, 3, 2, 5, 1, 2, 4, 5, 3, 2, 2, 5, 2, 2, 1, 2, 1, 3, 2, 1,\n",
       "       2, 1, 2, 4, 2, 4, 2, 2, 5, 1, 1, 1, 5, 5, 4, 3, 3, 5, 3, 5, 4, 3,\n",
       "       2, 2, 2, 4, 5, 5, 3, 2, 1, 2, 1, 4, 3, 3, 2, 1, 2, 2, 1, 2, 4, 1,\n",
       "       2, 2, 3, 5, 2, 3, 1, 5, 3, 5, 5, 5, 4, 3, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=TESTdata_y.astype(int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 4, 3, 4, 1, 2, 3, 2, 2, 1, 4, 4, 4, 1, 4, 2, 1, 3, 3, 4,\n",
       "       3, 2, 3, 3, 1, 1, 1, 2, 4, 2, 1, 1, 4, 1, 0, 0, 2, 4, 0, 1, 2, 1,\n",
       "       0, 1, 0, 3, 1, 4, 4, 4, 1, 2, 4, 2, 0, 1, 4, 4, 3, 0, 3, 2, 1, 1,\n",
       "       1, 1, 1, 4, 0, 2, 3, 4, 2, 4, 1, 1, 0, 1, 0, 1, 3, 2, 2, 2, 1, 1,\n",
       "       4, 0, 3, 4, 1, 3, 3, 4, 3, 0, 0, 0, 4, 0, 2, 3, 0, 1, 3, 4, 0, 3,\n",
       "       3, 3, 1, 1, 1, 4, 1, 2, 2, 1, 0, 1, 4, 1, 4, 3, 4, 3, 2, 4, 1, 1,\n",
       "       4, 1, 3, 2, 1, 1, 4, 1, 4, 4, 1, 3, 4, 0, 2, 2, 1, 2, 0, 1, 3, 4,\n",
       "       1, 1, 4, 4, 3, 1, 4, 3, 2, 1, 3, 1, 3, 0, 0, 2, 2, 4, 1, 0, 1, 4,\n",
       "       3, 0, 2, 3, 1, 2, 1, 2, 0, 2, 1, 4, 1, 1, 3, 3, 4, 1, 3, 4, 1, 1,\n",
       "       1, 0, 3, 2, 1, 4, 4, 4, 0, 0, 2, 0, 1, 1, 4, 1, 4, 4, 3, 3, 4, 3,\n",
       "       4, 2, 3, 0, 4, 1, 1, 1, 4, 0, 4, 2, 2, 2, 3, 4, 2, 4, 1, 1, 3, 1,\n",
       "       4, 0, 2, 1, 1, 3, 0, 3, 1, 4, 4, 1, 1, 4, 4, 4, 1, 2, 0, 4, 3, 4,\n",
       "       2, 4, 4, 2, 4, 1, 2, 1, 3, 1, 2, 2, 3, 0, 2, 0, 3, 3, 1, 0, 2, 4,\n",
       "       4, 1, 1, 4, 0, 4, 3, 2, 3, 3, 2, 1, 2, 4, 4, 2, 3, 4, 4, 3, 4, 3,\n",
       "       2, 0, 3, 1, 2, 4, 2, 2, 2, 1, 2, 3, 3, 4, 3, 0, 1, 1, 2, 4, 0, 1,\n",
       "       4, 2, 2, 4, 1, 4, 4, 2, 0, 4, 2, 4, 1, 4, 4, 4, 2, 1, 2, 1, 3, 0,\n",
       "       2, 4, 4, 2, 4, 0, 1, 4, 1, 4, 4, 1, 0, 4, 4, 0, 2, 1, 1, 3, 1, 4,\n",
       "       1, 4, 1, 3, 4, 1, 4, 2, 2, 4, 1, 0, 3, 2, 4, 4, 1, 0, 1, 3, 3, 1,\n",
       "       1, 1, 1, 1, 3, 4, 1, 4, 4, 0, 4, 2, 4, 4, 1, 1, 4, 3, 1, 0, 4, 1,\n",
       "       1, 1, 0, 1, 4, 1, 0, 0, 2, 1, 4, 4, 4, 2, 1, 3, 4, 1, 4, 4, 1, 2,\n",
       "       1, 3, 2, 4, 3, 4, 3, 4, 0, 1, 1, 3, 3, 2, 1, 1, 0, 2, 1, 3, 1, 4,\n",
       "       3, 3, 0, 1, 1, 3, 1, 4, 3, 1, 3, 3, 1, 2, 3, 4, 4, 2, 4, 4, 3, 1,\n",
       "       1, 2, 1, 1, 4, 0, 3, 1, 1, 4, 0, 4, 4, 1, 1, 1, 1, 3, 3, 4, 3, 4,\n",
       "       4, 3, 2, 0, 4, 4, 3, 0, 1, 4, 3, 2, 1, 2, 0, 3, 1, 2, 1, 1, 3, 1,\n",
       "       1, 1, 3, 2, 4, 4, 0, 2, 3, 4, 1, 0, 4, 1, 2, 4, 1, 3, 3, 0, 0, 2,\n",
       "       1, 1, 1, 3, 0, 4, 1, 2, 1, 0, 1, 3, 4, 1, 0, 2, 1, 4, 1, 3, 2, 0,\n",
       "       4, 1, 3, 4, 3, 0, 2, 4, 3, 0, 1, 3, 4, 2, 3, 4, 1, 1, 3, 4, 3, 1,\n",
       "       4, 2, 3, 0, 1, 4, 0, 1, 3, 2, 3, 4, 4, 1, 4, 1, 4, 4, 2, 1, 0, 1,\n",
       "       4, 4, 3, 1, 1, 4, 4, 1, 4, 4, 4, 1, 2, 3, 0, 1, 3, 2, 4, 3, 1, 4,\n",
       "       1, 1, 4, 4, 1, 4, 4, 1, 0, 1, 2, 2, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy before FS: 0.23\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_before = clustering_accuracy(labels,before_y_pred)\n",
    "print(f\"Clustering Accuracy before FS: {ClusteringACC_before:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 1: CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER: 0.23\n"
     ]
    }
   ],
   "source": [
    "# compare clustering vs labels\n",
    "ClusteringACC_CLEVER = clustering_accuracy(labels,CLEVER_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER: {ClusteringACC_CLEVER:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 2: CLeVer Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER Cluster: 0.23\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_CLEVERC = clustering_accuracy(labels,CLEVERC_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER Cluster: {ClusteringACC_CLEVERC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 3: CLeVer Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER Rank: 0.23\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_CLEVERR = clustering_accuracy(labels,CLEVERR_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER Rank: {ClusteringACC_CLEVERR:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
