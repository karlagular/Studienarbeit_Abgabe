{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_from_tsfile\n",
    "import numpy as np # for some mathematical operations\n",
    "def load_data(DATA_PATH,t):\n",
    "    if t=='train':\n",
    "        train_x, train_y = load_from_tsfile(DATA_PATH + \"/MotionSenseHAR/MotionSenseHAR_TRAIN.ts\")\n",
    "        return [train_x,train_y]\n",
    "    elif t=='test':\n",
    "        test_x, test_y = load_from_tsfile(DATA_PATH + \"/MotionSenseHAR/MotionSenseHAR_TEST.ts\")\n",
    "        return [test_x, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the load_data function\n",
    "[data, data_y] = load_data(r\"C:\\Users\\pappe\\OneDrive - IPH Hannover gGmbH\\General\\Privat\\Studienarbeit_Karla\\Studienarbeit_Code\\Studienarbeit_Code\\datasets\",'train')  # 'path', 'test'/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time series:\n",
      "[[ 1.528132  1.527992  1.527765 ...  1.242636  1.172438  1.088215]\n",
      " [-0.733896 -0.716987 -0.706999 ... -0.606728 -0.604834 -0.590965]\n",
      " [ 0.696372  0.677762  0.670951 ... -2.673003 -2.664214 -2.658315]\n",
      " ...\n",
      " [ 0.294894  0.219405  0.010714 ... -0.178695  0.016807  0.549265]\n",
      " [-0.184493  0.035846  0.134701 ...  0.007637  0.077783  0.142422]\n",
      " [ 0.377542  0.114866 -0.167808 ...  0.353873  0.264784 -0.060651]] \n",
      "\n",
      "First target:\n",
      "dws \n",
      "\n",
      "Shape of train dataset:\n",
      "(966, 12, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('First time series:')\n",
    "print(data[0],\"\\n\")\n",
    "print('First target:')\n",
    "print(data_y[0],\"\\n\")\n",
    "print('Shape of train dataset:') #(samples, features,timestamps) \n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "def standarize(data):\n",
    "    scaler = TimeSeriesScalerMeanVariance(mu=0.0, std=1.0)  # Standardize to mean=0, std=1\n",
    "    scaled_data_3d = scaler.fit_transform(data)\n",
    "    return scaled_data_3d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (966, 12, 1000)\n",
      "Reshaped shape: (966, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Transform from (samples, features,timestamps) to (samples, timestamps, features) to apply standarisation\n",
    "reshaped_data = np.transpose(data, (0, 2, 1))\n",
    "print(\"Original shape:\", data.shape)          # (instances, features, timepoints)\n",
    "print(\"Reshaped shape:\", reshaped_data.shape) # (instances, timepoints, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time series:\n",
      "[[ 6.51829386e-01 -1.67061485e-01  7.02820502e-01 ...  6.56908619e-01\n",
      "  -6.39617182e-01  9.59936638e-01]\n",
      " [ 6.51252682e-01 -6.17606338e-02  6.92783970e-01 ...  4.37960751e-01\n",
      "   1.43309164e-01  1.46918625e-01]\n",
      " [ 6.50317597e-01  4.39667952e-04  6.89110739e-01 ... -1.67325443e-01\n",
      "   4.94568741e-01 -7.27995923e-01]\n",
      " ...\n",
      " [-5.24219044e-01  6.24877639e-01 -1.11431238e+00 ... -7.16686233e-01\n",
      "   4.30746647e-02  8.86677858e-01]\n",
      " [-8.13386835e-01  6.36672530e-01 -1.10957240e+00 ... -1.49653340e-01\n",
      "   2.92323102e-01  6.10935263e-01]\n",
      " [-1.16032804e+00  7.23041771e-01 -1.10639102e+00 ...  1.39468483e+00\n",
      "   5.22003622e-01 -3.96330406e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_data=standarize(reshaped_data)\n",
    "# scaled_data\n",
    "print('First time series:')\n",
    "print(scaled_data[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: intrinsic metrics before vs. after Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS:\n",
    "* Representation Entropy correlation based\n",
    "* Variance\n",
    "* Redundancy Rate RED\n",
    "\n",
    "TO DO:\n",
    "* Information Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation Entropy\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def compute_representation_entropy(data):\n",
    "    \"\"\"\n",
    "    Compute Representation Entropy (RE) of a multivariate dataset.\n",
    "    \n",
    "    Args:\n",
    "        data (numpy.ndarray): 2D-Data with shape (samples, features).\n",
    "    \n",
    "    Returns:\n",
    "        float: Representation Entropy (RE).\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the covariance matrix of the dataset (features x features)\n",
    "    covariance_matrix = np.cov(data, rowvar=False)  # rowvar=False means variables are columns\n",
    "\n",
    "    # # Step 2: Compute eigenvalues of the covariance matrix\n",
    "    # eigenvalues = np.linalg.eigvals(covariance_matrix) THIS METHOD WAS REPLACED BC OF INSTABILITY\n",
    "    eigenvalues, eigenvectors = eigh(covariance_matrix)\n",
    "\n",
    "    # Step 3: Normalize the eigenvalues to act as probabilities\n",
    "    eigenvalues_sum = np.sum(eigenvalues)\n",
    "    normalized_eigenvalues = eigenvalues / eigenvalues_sum\n",
    "\n",
    "    # Step 4: Compute Representation Entropy using the formula\n",
    "    representation_entropy = -np.sum(normalized_eigenvalues * np.log(normalized_eigenvalues))\n",
    "\n",
    "    return representation_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to flatten the Time Dimension\n",
    "data_flattened = scaled_data.reshape(-1, scaled_data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(966000, 12)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.332264108310466"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_representation_entropy(data_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall variance: 0.9999999999999986\n",
      "Redundancy Rate (Correlation-Based): 0.07660471326380351\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# calculate variance\n",
    "overall_variance = data_flattened.var().mean()\n",
    "print('overall variance:', overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = pd.DataFrame(data_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "avg_corr = (corr_matrix.values.sum() - len(corr_matrix)) / (len(corr_matrix) * (len(corr_matrix) - 1))\n",
    "redundancy_rate = avg_corr\n",
    "print(\"Redundancy Rate (Correlation-Based):\", redundancy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TEST dataset\n",
    "[TESTdata, TESTdata_y] = load_data(r\"C:\\Users\\pappe\\OneDrive - IPH Hannover gGmbH\\General\\Privat\\Studienarbeit_Karla\\Studienarbeit_Code\\Studienarbeit_Code\\datasets\",'test')  # 'path', 'test'/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (966, 12, 1000)\n",
      "Reshaped shape: (966, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the TEST data\n",
    "\n",
    "reshaped_TESTdata = np.transpose(TESTdata, (0, 2, 1))\n",
    "print(\"Original shape:\", data.shape)          # (instances, features, timepoints)\n",
    "print(\"Reshaped shape:\", reshaped_data.shape) # (instances, timepoints, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_TESTdata=standarize(reshaped_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before Representation entropy:  2.333380847639658\n",
      "before overall variance: 0.9999999999999997\n",
      "before Redundancy Rate (Correlation-Based): 0.07103940208190185\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for original data_TEST\n",
    "\n",
    "# Compute representation entropy\n",
    "before_TESTdata_flattened = scaled_TESTdata.reshape(-1, scaled_TESTdata.shape[2])\n",
    "before_representation_entropy = compute_representation_entropy(before_TESTdata_flattened)\n",
    "print('before Representation entropy: ', before_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "before_overall_variance = before_TESTdata_flattened.var().mean()\n",
    "print('before overall variance:', before_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "before_corr_matrix = pd.DataFrame(before_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "before_avg_corr = (before_corr_matrix.values.sum() - len(before_corr_matrix)) / (len(before_corr_matrix) * (len(before_corr_matrix) - 1))\n",
    "before_redundancy_rate = before_avg_corr\n",
    "print(\"before Redundancy Rate (Correlation-Based):\", before_redundancy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265000, 12)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(before_TESTdata_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection 1: CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved Code\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "def compute_dcpcs(data, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compute Descriptive Common Principal Components (DCPCs) for a set of multivariate time series.\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray of shape (num_samples, num_features, time_steps), the time-series dataset.\n",
    "    - variance_threshold: float, the cumulative variance explained to determine the number of PCs.\n",
    "\n",
    "    Returns:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    \"\"\"\n",
    "    num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "    # Step 1: Compute PCs for each MTS item\n",
    "    pc_matrices = []  # Store PC loadings for each sample\n",
    "    for sample in range(num_samples):\n",
    "        # Compute correlation matrix for each sample\n",
    "        correlation_matrix = np.corrcoef(data[sample])\n",
    "        # Perform PCA on the correlation matrix\n",
    "        pca = PCA()\n",
    "        pca.fit(correlation_matrix)\n",
    "        pc_matrices.append(pca.components_[:pca.n_components_])\n",
    "\n",
    "    # Step 2: Compute DCPCs across all samples using SVD\n",
    "    all_pc_matrices = np.concatenate(pc_matrices, axis=0)  # Combine PC loadings from all samples\n",
    "    dcpc_covariance = all_pc_matrices.T @ all_pc_matrices\n",
    "    eigvals, eigvecs = np.linalg.eigh(dcpc_covariance)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, sorted_indices]  # Sort eigenvectors by eigenvalues\n",
    "\n",
    "    # Select DCPCs explaining the desired variance threshold\n",
    "    cumulative_variance = np.cumsum(eigvals[sorted_indices]) / np.sum(eigvals)\n",
    "    num_dcpcs = np.searchsorted(cumulative_variance, variance_threshold) + 1\n",
    "    dcpc_loadings = eigvecs[:, :num_dcpcs].T\n",
    "\n",
    "    return dcpc_loadings\n",
    "\n",
    "def cluster_features(dcpc_loadings, n_clusters):\n",
    "    \"\"\"\n",
    "    Cluster features based on their DCPC loadings using K-means.\n",
    "\n",
    "    Parameters:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    - n_clusters: int, number of clusters.\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: ndarray of shape (num_features,), cluster assignments for each feature.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(dcpc_loadings.T)\n",
    "    return cluster_labels\n",
    "\n",
    "def rank_features(dcpc_loadings, cluster_labels):\n",
    "    \"\"\"\n",
    "    Rank features within each cluster based on their contribution to DCPCs.\n",
    "\n",
    "    Parameters:\n",
    "    - dcpc_loadings: ndarray of shape (num_dcpcs, num_features), loadings of the DCPCs.\n",
    "    - cluster_labels: ndarray of shape (num_features,), cluster assignments for each feature.\n",
    "\n",
    "    Returns:\n",
    "    - ranked_features: dict, keys are cluster labels, values are ranked feature indices.\n",
    "    \"\"\"\n",
    "    ranked_features = {}\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        cluster_loadings = dcpc_loadings[:, cluster_indices]\n",
    "        scores = np.linalg.norm(cluster_loadings, axis=0)  # L2 norm of loadings\n",
    "        ranking = cluster_indices[np.argsort(scores)[::-1]]  # Sort by descending contribution\n",
    "        ranked_features[cluster] = ranking\n",
    "    return ranked_features\n",
    "\n",
    "def select_top_features(ranked_features, top_n=1):\n",
    "    \"\"\"\n",
    "    Select top-ranked features from each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - ranked_features: dict, keys are cluster labels, values are ranked feature indices.\n",
    "    - top_n: int, number of features to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: list, indices of selected features.\n",
    "    \"\"\"\n",
    "    selected_features = []\n",
    "    for features in ranked_features.values():\n",
    "        selected_features.extend(features[:top_n])\n",
    "    return selected_features\n",
    "\n",
    "def clever_hybrid(data, variance_threshold=0.8, n_clusters=None, top_n=1):\n",
    "    \"\"\"\n",
    "    Perform feature selection using the CLeVer-Hybrid algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray of shape (num_samples, num_features, time_steps), the time-series dataset.\n",
    "    - variance_threshold: float, variance threshold for selecting DCPCs.\n",
    "    - n_clusters: int, number of clusters (if None, sqrt of num_features is used).\n",
    "    - top_n: int, number of features to select from each cluster.\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: list, indices of selected features.\n",
    "    \"\"\"\n",
    "    num_samples, num_features, _ = data.shape\n",
    "    if n_clusters is None:\n",
    "        n_clusters = int(np.sqrt(num_features))\n",
    "\n",
    "    # Step 1: Compute DCPCs\n",
    "    dcpc_loadings = compute_dcpcs(data, variance_threshold)\n",
    "\n",
    "    # Step 2: Cluster features based on DCPC loadings\n",
    "    cluster_labels = cluster_features(dcpc_loadings, n_clusters)\n",
    "\n",
    "    # Step 3: Rank features within clusters\n",
    "    ranked_features = rank_features(dcpc_loadings, cluster_labels)\n",
    "\n",
    "    # Step 4: Select top features from each cluster\n",
    "    selected_features = select_top_features(ranked_features, top_n)\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(966, 12, 1000)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data_ift= np.transpose(scaled_data, (0, 2, 1))\n",
    "np.shape(scaled_data_ift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features CLeVer Hybrid:  [7, 11, 10, 0]\n"
     ]
    }
   ],
   "source": [
    "selected_features_CLeVerH=clever_hybrid(scaled_data_ift, n_clusters=4, top_n=1)\n",
    "print(\"Selected features CLeVer Hybrid: \", selected_features_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 1000, 12)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (265, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerH = scaled_TESTdata[:, :, selected_features_CLeVerH]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Hybrid Representation entropy:  1.3824341826604127\n",
      "CLEVER Hybrid overall variance: 1.0000000000000002\n",
      "CLEVER Hybrid Redundancy Rate (Correlation-Based): 0.037143214580118634\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerH\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERH_TESTdata_flattened = selected_TESTdata_CLeVerH.reshape(-1, selected_TESTdata_CLeVerH.shape[2])\n",
    "CLEVERH_representation_entropy = compute_representation_entropy(CLEVERH_TESTdata_flattened)\n",
    "print('CLEVER Hybrid Representation entropy: ', CLEVERH_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERH_overall_variance = CLEVERH_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Hybrid overall variance:', CLEVERH_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERH_corr_matrix = pd.DataFrame(CLEVERH_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERH_avg_corr = (CLEVERH_corr_matrix.values.sum() - len(CLEVERH_corr_matrix)) / (len(CLEVERH_corr_matrix) * (len(CLEVERH_corr_matrix) - 1))\n",
    "CLEVERH_redundancy_rate = CLEVERH_avg_corr\n",
    "print(\"CLEVER Hybrid Redundancy Rate (Correlation-Based):\", CLEVERH_redundancy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265000, 4)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(CLEVERH_TESTdata_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection CLeVer CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# def compute_dcpcs(data, variance_threshold=0.8):\n",
    "#     \"\"\"\n",
    "#     Compute Descriptive Common Principal Components (DCPCs).\n",
    "\n",
    "#     Parameters:\n",
    "#     - data: np.array of shape (samples, features, time_steps)\n",
    "#     - variance_threshold: Minimum variance explained by selected PCs\n",
    "\n",
    "#     Returns:\n",
    "#     - dcpc_loadings: Matrix of DCPC loadings for features\n",
    "#     \"\"\"\n",
    "#     num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "#     # Step 1: Perform PCA for each sample's time-series data\n",
    "#     pc_matrices = []  # Store the PC loadings for all samples\n",
    "#     for sample in range(num_samples):\n",
    "#         sample_data = data[sample]  # Shape: (features, time_steps)\n",
    "#         pca = PCA()\n",
    "#         pca.fit(sample_data.T)\n",
    "        \n",
    "#         # Select the number of PCs to retain (based on variance threshold)\n",
    "#         cum_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "#         num_pcs = np.searchsorted(cum_variance, variance_threshold) + 1\n",
    "#         pc_matrices.append(pca.components_[:num_pcs])  # Retain only the top PCs\n",
    "\n",
    "#     # Step 2: Compute the DCPC loadings (common across all samples)\n",
    "#     H = np.zeros((num_features, num_features))\n",
    "#     for pc_matrix in pc_matrices:\n",
    "#         H += pc_matrix.T @ pc_matrix\n",
    "\n",
    "#     eigvals, eigvecs = np.linalg.eigh(H)  # Eigen decomposition\n",
    "#     eigvecs = eigvecs[:, ::-1]  # Sort eigenvectors in descending order of eigenvalues\n",
    "\n",
    "#     return eigvecs.T  # DCPC loadings (features x components)\n",
    "\n",
    "def clever_cluster(data, n_clusters=None, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    CLeVer-Cluster implementation.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array of shape (samples, features, time_steps)\n",
    "    - n_clusters: Number of feature clusters (if None, heuristic is used)\n",
    "    - variance_threshold: Minimum variance explained by selected PCs\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: List of representative feature indices for each cluster\n",
    "    \"\"\"\n",
    "    num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "    # Step 1: Compute DCPC loadings\n",
    "    dcpc_loadings = compute_dcpcs(data, variance_threshold=variance_threshold)  # Shape: (components, features)\n",
    "\n",
    "    # Step 2: Transpose DCPC loadings to cluster features\n",
    "    feature_embeddings = dcpc_loadings.T  # Shape: (features, components)\n",
    "\n",
    "    # Step 3: Determine number of clusters\n",
    "    if n_clusters is None:\n",
    "        n_clusters = int(np.sqrt(num_features))  # Heuristic for cluster count\n",
    "\n",
    "    # Step 4: Perform K-means clustering on DCPC loadings\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_embeddings)\n",
    "\n",
    "    # Step 5: Select representative features (closest to cluster centroids)\n",
    "    selected_features = []\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        centroid = kmeans.cluster_centers_[cluster]\n",
    "\n",
    "        # Find the feature closest to the centroid\n",
    "        distances = np.linalg.norm(feature_embeddings[cluster_indices] - centroid, axis=1)\n",
    "        representative_feature = cluster_indices[np.argmin(distances)]\n",
    "        selected_features.append(representative_feature)\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLeVer Cluster Selected feature indices: [7, 4, 10, 0]\n"
     ]
    }
   ],
   "source": [
    "#  Usage\n",
    "# Assuming `data` is a NumPy array with shape (samples, features, time_steps)\n",
    "selected_features_CLeVerC = clever_cluster(scaled_data_ift, n_clusters=4)\n",
    "print(f'CLeVer Cluster Selected feature indices: {selected_features_CLeVerC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 1000, 12)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (265, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerC = scaled_TESTdata[:, :, selected_features_CLeVerC]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Cluster Representation entropy:  1.381493946362083\n",
      "CLEVER Cluster overall variance: 1.0000000000000002\n",
      "CLEVER Cluster Redundancy Rate (Correlation-Based): 0.04656726879094227\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerC\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERC_TESTdata_flattened = selected_TESTdata_CLeVerC.reshape(-1, selected_TESTdata_CLeVerC.shape[2])\n",
    "CLEVERC_representation_entropy = compute_representation_entropy(CLEVERC_TESTdata_flattened)\n",
    "print('CLEVER Cluster Representation entropy: ', CLEVERC_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERC_overall_variance = CLEVERC_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Cluster overall variance:', CLEVERC_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERC_corr_matrix = pd.DataFrame(CLEVERC_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERC_avg_corr = (CLEVERC_corr_matrix.values.sum() - len(CLEVERC_corr_matrix)) / (len(CLEVERC_corr_matrix) * (len(CLEVERC_corr_matrix) - 1))\n",
    "CLEVERC_redundancy_rate = CLEVERC_avg_corr\n",
    "print(\"CLEVER Cluster Redundancy Rate (Correlation-Based):\", CLEVERC_redundancy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection CLeVer Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# def compute_dcpcs(data, variance_threshold=0.8):\n",
    "#     \"\"\"\n",
    "#     Compute Descriptive Common Principal Components (DCPCs).\n",
    "\n",
    "#     Parameters:\n",
    "#     - data: np.array of shape (samples, features, time_steps)\n",
    "#     - variance_threshold: Minimum variance explained by selected PCs\n",
    "\n",
    "#     Returns:\n",
    "#     - dcpc_loadings: Matrix of DCPC loadings for features\n",
    "#     \"\"\"\n",
    "#     num_samples, num_features, time_steps = data.shape\n",
    "\n",
    "#     # Step 1: Perform PCA for each sample's time-series data\n",
    "#     pc_matrices = []  # Store the PC loadings for all samples\n",
    "#     for sample in range(num_samples):\n",
    "#         sample_data = data[sample]  # Shape: (features, time_steps)\n",
    "#         pca = PCA()\n",
    "#         pca.fit(sample_data.T)\n",
    "        \n",
    "#         # Select the number of PCs to retain (based on variance threshold)\n",
    "#         cum_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "#         num_pcs = np.searchsorted(cum_variance, variance_threshold) + 1\n",
    "#         pc_matrices.append(pca.components_[:num_pcs])  # Retain only the top PCs\n",
    "\n",
    "#     # Step 2: Compute the DCPC loadings (common across all samples)\n",
    "#     H = np.zeros((num_features, num_features))\n",
    "#     for pc_matrix in pc_matrices:\n",
    "#         H += pc_matrix.T @ pc_matrix\n",
    "\n",
    "#     eigvals, eigvecs = np.linalg.eigh(H)  # Eigen decomposition\n",
    "#     eigvecs = eigvecs[:, ::-1]  # Sort eigenvectors in descending order of eigenvalues\n",
    "\n",
    "#     return eigvecs.T  # DCPC loadings (features x components)\n",
    "\n",
    "\n",
    "def clever_ranking(data, num_features_to_select=5, variance_threshold=0.8):\n",
    "    \"\"\"\n",
    "    CLeVer Ranking method for feature selection.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array of shape (samples, features, time_steps)\n",
    "    - num_features_to_select: Number of top-ranked features to select\n",
    "    - variance_threshold: Variance threshold for PCA\n",
    "\n",
    "    Returns:\n",
    "    - selected_features: List of indices of the top-ranked features\n",
    "    \"\"\"\n",
    "    # Step 1: Compute DCPC loadings\n",
    "    dcpc_loadings = compute_dcpcs(data)\n",
    "\n",
    "    # Step 2: Rank features based on their contribution to the DCPCs\n",
    "    feature_scores = np.linalg.norm(dcpc_loadings, axis=1)  # L2 norm of DCPC loadings\n",
    "    ranked_features = np.argsort(feature_scores)[::-1]  # Sort in descending order\n",
    "\n",
    "    # Step 3: Select top features\n",
    "    selected_features = ranked_features[:num_features_to_select]\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLeVer Rank Selected feature indices: [1 8 7 6]\n"
     ]
    }
   ],
   "source": [
    "selected_features_CLeVerR = clever_ranking(scaled_data_ift, num_features_to_select=4)\n",
    "print(f'CLeVer Rank Selected feature indices: {selected_features_CLeVerR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered TEST dataset shape:  (265, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filter the TEST Dataset according to the selected features from CLeVer\n",
    "selected_TESTdata_CLeVerR = scaled_TESTdata[:, :, selected_features_CLeVerR]\n",
    "print('Filtered TEST dataset shape: ', np.shape(selected_TESTdata_CLeVerR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Cluster Representation entropy:  1.3789000451618967\n",
      "CLEVER Cluster overall variance: 0.9999999999999998\n",
      "CLEVER Cluster Redundancy Rate (Correlation-Based): 0.05296186142263156\n"
     ]
    }
   ],
   "source": [
    "# Compute all intrinsic metrics again for selected_TESTdata_CLeVerR\n",
    "\n",
    "# Compute representation entropy\n",
    "CLEVERR_TESTdata_flattened = selected_TESTdata_CLeVerR.reshape(-1, selected_TESTdata_CLeVerR.shape[2])\n",
    "CLEVERR_representation_entropy = compute_representation_entropy(CLEVERR_TESTdata_flattened)\n",
    "print('CLEVER Cluster Representation entropy: ', CLEVERR_representation_entropy)\n",
    "\n",
    "# calculate variance\n",
    "CLEVERR_overall_variance = CLEVERR_TESTdata_flattened.var().mean()\n",
    "print('CLEVER Cluster overall variance:', CLEVERR_overall_variance)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "CLEVERR_corr_matrix = pd.DataFrame(CLEVERR_TESTdata_flattened).corr().abs()\n",
    "# Calculate average absolute correlation (excluding the diagonal)\n",
    "CLEVERR_avg_corr = (CLEVERR_corr_matrix.values.sum() - len(CLEVERR_corr_matrix)) / (len(CLEVERR_corr_matrix) * (len(CLEVERR_corr_matrix) - 1))\n",
    "CLEVERR_redundancy_rate = CLEVERR_avg_corr\n",
    "print(\"CLEVER Cluster Redundancy Rate (Correlation-Based):\", CLEVERR_redundancy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Perform Timeseries-k-Means and evaluate clustering performance UNSUPERVISED\n",
    "\n",
    "TO DO: \n",
    "Check required cluster input shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusterin evaluation Metrics:\n",
    "* Silhouette \n",
    "* Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTW Time series clsutering erfolgreich 133 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW k-means\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "print(\"DTW k-means\")\n",
    "sdtw_km = TimeSeriesKMeans(n_clusters=6,\n",
    "                           metric=\"dtw\",\n",
    "                           verbose=True,\n",
    "                           random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = sdtw_km.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering should be done on the TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 1000, 12)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thefit_predict(X, y=None)\n",
    "Fit k-means clustering using X and then predict the closest cluster each time series in X belongs to.\n",
    "\n",
    "Parameters:\n",
    "Xarray-like of shape=(n_ts, sz, d)\n",
    "n_ts: instance, sz:timestamps, d:features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16085.256 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800.553 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8689.389 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8646.228 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8646.228 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   12.9s\n"
     ]
    }
   ],
   "source": [
    "before_y_pred = sdtw_km.fit_predict(scaled_TESTdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 5, 5, 1, 1, 3, 4, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 3, 0, 3, 0, 5, 0, 3, 3, 0, 3, 0, 0, 3, 3, 0, 5,\n",
       "       0, 3, 3, 5, 3, 3, 2, 3, 0, 5, 5, 0, 3, 0, 5, 3, 5, 5, 3, 5, 5, 5,\n",
       "       3, 3, 3, 3, 3, 4, 4, 2, 2, 3, 3, 3, 5, 5, 3, 5, 5, 5, 5, 5, 3, 4,\n",
       "       0, 3, 3, 3, 5, 4, 4, 3, 2, 0, 0, 5, 5, 5, 5, 3, 5, 0, 3, 3, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 4, 0, 3, 3, 0, 5, 2, 2, 3, 2, 4, 3, 0, 1, 0,\n",
       "       5, 0, 2, 0, 4, 2, 2, 3, 3, 3, 0, 5, 2, 2, 4, 3, 3, 4, 2, 2, 3, 0,\n",
       "       5, 3, 3, 3, 3, 3, 3, 2, 3, 4, 0, 5, 0, 2, 3, 2, 0, 5, 0, 3, 5, 4,\n",
       "       3, 3, 3, 0, 3, 2, 0, 3, 5, 3, 2, 3, 3, 5, 5, 1, 1, 4, 2, 4, 1, 2,\n",
       "       4, 4, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1,\n",
       "       4, 4, 1, 1, 1, 1, 4, 1, 2, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4,\n",
       "       1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.00186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "labels = before_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdata_flattened_instances = scaled_TESTdata.reshape(scaled_TESTdata.shape[0], -1)  \n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_TESTdata_flattened_instances, labels, metric='euclidean')\n",
    "print(f\"Silhouette Score: {silhouette_avg:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 7.68617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "db_index = davies_bouldin_score(scaled_TESTdata_flattened_instances, labels)\n",
    "print(f\"Davies-Bouldin Index: {db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 1000, 4)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_TESTdata_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4163.076 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478.618 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2441.339 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431.729 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431.729 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   10.1s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVERH_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Silhouette Score: -0.00291\n",
      "CLEVER Davies-Bouldin Index: 8.45873\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CH = CLEVERH_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCH_flattened_instances = selected_TESTdata_CLeVerH.reshape(selected_TESTdata_CLeVerH.shape[0], -1)  \n",
    "\n",
    "CLEVERH_silhouette_avg = silhouette_score(scaled_TESTdataCH_flattened_instances, labels_CH, metric='euclidean')\n",
    "print(f\"CLEVER Hybrid Silhouette Score: {CLEVERH_silhouette_avg:.5f}\")\n",
    "CLEVERH_db_index = davies_bouldin_score(scaled_TESTdataCH_flattened_instances, labels_CH)\n",
    "print(f\"CLEVER Hybrid Davies-Bouldin Index: {CLEVERH_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLeVer Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4061.476 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2322.929 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251.083 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2229.514 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209.777 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201.411 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199.057 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197.776 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197.776 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVERC_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Silhouette Score: 0.00473\n",
      "CLEVER Davies-Bouldin Index: 7.28129\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CC = CLEVERC_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCC_flattened_instances = selected_TESTdata_CLeVerC.reshape(selected_TESTdata_CLeVerC.shape[0], -1)  \n",
    "\n",
    "CLEVERC_silhouette_avg = silhouette_score(scaled_TESTdataCC_flattened_instances, labels_CC, metric='euclidean')\n",
    "print(f\"CLEVER Cluster Silhouette Score: {CLEVERC_silhouette_avg:.5f}\")\n",
    "CLEVERC_db_index = davies_bouldin_score(scaled_TESTdataCC_flattened_instances, labels_CC)\n",
    "print(f\"CLEVER Cluster Davies-Bouldin Index: {CLEVERC_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLeVer Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982.516 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392.891 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360.331 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351.837 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2349.271 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347.229 --> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347.229 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    8.5s\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "CLEVERR_y_pred = sdtw_km.fit_predict(selected_TESTdata_CLeVerR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEVER Rank Silhouette Score: 0.00020\n",
      "CLEVER Rank Davies-Bouldin Index: 7.71866\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering metrics\n",
    "labels_CR = CLEVERR_y_pred  # Cluster labels from the model\n",
    "# Flatten the time series for silhouette_score into (instances,timestamps*features)\n",
    "scaled_TESTdataCR_flattened_instances = selected_TESTdata_CLeVerR.reshape(selected_TESTdata_CLeVerR.shape[0], -1)  \n",
    "\n",
    "CLEVERR_silhouette_avg = silhouette_score(scaled_TESTdataCR_flattened_instances, labels_CR, metric='euclidean')\n",
    "print(f\"CLEVER Rank Silhouette Score: {CLEVERR_silhouette_avg:.5f}\")\n",
    "CLEVERR_db_index = davies_bouldin_score(scaled_TESTdataCR_flattened_instances, labels_CR)\n",
    "print(f\"CLEVER Rank Davies-Bouldin Index: {CLEVERR_db_index:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validierung mit clustering accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare clustering vs labels\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(true_labels, predicted_labels):\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Use the Hungarian algorithm to find the optimal assignment of clusters\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)  # Maximize the matching (negative to maximize)\n",
    "    \n",
    "    # Calculate accuracy based on optimal matching\n",
    "    accuracy = cm[row_ind, col_ind].sum() / len(true_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dws', 'dws', 'dws', 'dws', 'dws', 'dws', 'dws', 'dws', 'dws',\n",
       "       'dws', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog',\n",
       "       'jog', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog', 'jog',\n",
       "       'jog', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit', 'sit',\n",
       "       'sit', 'sit', 'sit', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std', 'std',\n",
       "       'std', 'std', 'ups', 'ups', 'ups', 'ups', 'ups', 'ups', 'ups',\n",
       "       'ups', 'ups', 'ups', 'ups', 'ups', 'ups', 'ups', 'ups', 'ups',\n",
       "       'ups', 'ups', 'ups', 'ups', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk', 'wlk',\n",
       "       'wlk', 'wlk', 'wlk', 'wlk'], dtype='<U3')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTdata_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 5, 5, 1, 1, 3, 4, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 3, 0, 3, 0, 5, 0, 3, 3, 0, 3, 0, 0, 3, 3, 0, 5,\n",
       "       0, 3, 3, 5, 3, 3, 2, 3, 0, 5, 5, 0, 3, 0, 5, 3, 5, 5, 3, 5, 5, 5,\n",
       "       3, 3, 3, 3, 3, 4, 4, 2, 2, 3, 3, 3, 5, 5, 3, 5, 5, 5, 5, 5, 3, 4,\n",
       "       0, 3, 3, 3, 5, 4, 4, 3, 2, 0, 0, 5, 5, 5, 5, 3, 5, 0, 3, 3, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 4, 0, 3, 3, 0, 5, 2, 2, 3, 2, 4, 3, 0, 1, 0,\n",
       "       5, 0, 2, 0, 4, 2, 2, 3, 3, 3, 0, 5, 2, 2, 4, 3, 3, 4, 2, 2, 3, 0,\n",
       "       5, 3, 3, 3, 3, 3, 3, 2, 3, 4, 0, 5, 0, 2, 3, 2, 0, 5, 0, 3, 5, 4,\n",
       "       3, 3, 3, 0, 3, 2, 0, 3, 5, 3, 2, 3, 3, 5, 5, 1, 1, 4, 2, 4, 1, 2,\n",
       "       4, 4, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 1, 1,\n",
       "       4, 4, 1, 1, 1, 1, 4, 1, 2, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4,\n",
       "       1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_numeric(labels):\n",
    "    \"\"\"\n",
    "    Convert string labels to numeric labels based on a predefined mapping.\n",
    "\n",
    "    Args:\n",
    "        labels (list or array): The string labels to be converted.\n",
    "\n",
    "    Returns:\n",
    "        list: Numeric labels.\n",
    "    \"\"\"\n",
    "    # Define the mapping\n",
    "    label_mapping = {\n",
    "        'dws': 0,\n",
    "        'jog': 1,\n",
    "        'sit': 2,\n",
    "        'std': 3,\n",
    "        'ups': 4,\n",
    "        'wlk': 5\n",
    "    }\n",
    "    \n",
    "    # Map labels\n",
    "    numeric_labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "    return numeric_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['dws' 'dws' 'dws' 'dws' 'dws' 'dws' 'dws' 'dws' 'dws' 'dws' 'jog' 'jog'\n",
      " 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog' 'jog'\n",
      " 'jog' 'jog' 'jog' 'jog' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit' 'sit'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std'\n",
      " 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'std' 'ups'\n",
      " 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups'\n",
      " 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'ups' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk'\n",
      " 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk'\n",
      " 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk'\n",
      " 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk'\n",
      " 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk' 'wlk'\n",
      " 'wlk']\n",
      "Numeric labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "numeric_labels = convert_labels_to_numeric(TESTdata_y)\n",
    "print(\"Original labels:\", TESTdata_y)\n",
    "print(\"Numeric labels:\", numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy before FS: 0.39\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_before = clustering_accuracy(numeric_labels,before_y_pred)\n",
    "print(f\"Clustering Accuracy before FS: {ClusteringACC_before:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 1: CLeVer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER Hybrid: 0.37\n"
     ]
    }
   ],
   "source": [
    "# compare clustering vs labels\n",
    "ClusteringACC_CLEVERH = clustering_accuracy(numeric_labels,CLEVERH_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER Hybrid: {ClusteringACC_CLEVERH:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 2: CLeVer Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER Cluster: 0.38\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_CLEVERC = clustering_accuracy(numeric_labels,CLEVERC_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER Cluster: {ClusteringACC_CLEVERC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS 3: CLeVer Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy CLEVER Rank: 0.39\n"
     ]
    }
   ],
   "source": [
    "ClusteringACC_CLEVERR = clustering_accuracy(numeric_labels,CLEVERR_y_pred)\n",
    "print(f\"Clustering Accuracy CLEVER Rank: {ClusteringACC_CLEVERR:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
